name: Terraform Workflow

on:
  push:
    branches:
      - main

jobs:
  terraform:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.9.4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init -upgrade

    - name: Terraform Refresh
      working-directory: ./terraform
      run: terraform refresh

    - name: Terraform Apply
      working-directory: ./terraform
      run: terraform apply -auto-approve

    - name: Check Terraform version
      run: terraform version
    
    - name: Output Terraform JSON
      working-directory: ./terraform
      run: |
        terraform output -json > filtered_terraform_output.json

    - name: Commit and Push JSON Files
      working-directory: ./terraform
      run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add filtered_terraform_output.json
          git commit -m "Add Terraform output JSON file"
          git push https://x-access-token:${{ secrets.PERSONAL_ACCESS_TOKEN }}@github.com/sruthianem89/Cloud-Resume-Challenge.git
      env:
          GITHUB_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
      

    - name: Extract Terraform Outputs
      id: extract_outputs
      working-directory: ./terraform
      run: |
          if [ -f filtered_terraform_output.json ]; then
            echo "filtered_terraform_output.json exists and its contents are:"
            cat filtered_terraform_output.json
          
            dynamodb_table_name=$(python3 -c "import json; import sys; print(json.load(sys.stdin)['dynamodb_table_name']['value'])" < filtered_terraform_output.json)
            initialize_function_url=$(python3 -c "import json; import sys; print(json.load(sys.stdin)['initialize_dynamodb_url']['value'])" < filtered_terraform_output.json)
            lambda_function_url=$(python3 -c "import json; import sys; print(json.load(sys.stdin)['lambda_function_url']['value'])" < filtered_terraform_output.json)
            bucket_name=$(python3 -c "import json; import sys; print(json.load(sys.stdin)['bucket_name']['value'])" < filtered_terraform_output.json)

            
            echo "DYNAMODB_TABLE_NAME=$dynamodb_table_name"
            echo "INITIALIZE_FUNCTION_URL=$initialize_function_url"
            echo "LAMBDA_FUNCTION_URL=$lambda_function_url"
            echo "BUCKET_NAME=$bucket_name"
  
            echo "DYNAMODB_TABLE_NAME=$dynamodb_table_name" >> $GITHUB_ENV
            echo "INITIALIZE_FUNCTION_URL=$initialize_function_url" >> $GITHUB_ENV
            echo "LAMBDA_FUNCTION_URL=$lambda_function_url" >> $GITHUB_ENV
            echo "BUCKET_NAME=$bucket_name" >> $GITHUB_ENV
          else
            echo "terraform_output.json not found"
            exit 1
          fi

    - name: Escape special characters
      run: |
            escape_sed() {
              echo "$1" | sed 's/[&/\]/\\&/g'
            }

            lambda_function_url=$(escape_sed "${{ env.LAMBDA_FUNCTION_URL }}")
            initialize_function_url=$(escape_sed "${{ env.INITIALIZE_FUNCTION_URL }}")
            dynamodb_table_name=$(escape_sed "${{ env.DYNAMODB_TABLE_NAME }}")
            bucket_name=$(escape_sed "${{ env.BUCKET_NAME }}")
            
            echo "lambda_function_url=$lambda_function_url" >> $GITHUB_ENV
            echo "initialize_function_url=$initialize_function_url" >> $GITHUB_ENV
            echo "dynamodb_table_name=$dynamodb_table_name" >> $GITHUB_ENV
            echo "bucket_name=$bucket_name" >> $GITHUB_ENV

      env:
        LAMBDA_FUNCTION_URL: ${{ env.LAMBDA_FUNCTION_URL }}
        INITIALIZE_FUNCTION_URL: ${{ env.INITIALIZE_FUNCTION_URL }}
        DYNAMODB_TABLE_NAME: ${{ env.DYNAMODB_TABLE_NAME }}
        BUCKET_NAME: ${{ env.BUCKET_NAME }}

    - name: Update scripts.js with dynamic parameters
      if: ${{ env.LAMBDA_FUNCTION_URL != '' && env.INITIALIZE_FUNCTION_URL != '' && env.DYNAMODB_TABLE_NAME != '' && env.BUCKET_NAME != '' }}
      working-directory: ./frontend/js
      run: |
        
        
        # Update the scripts.js file
        sed -i "s|LAMBDA_FUNCTION_URL|${{ env.LAMBDA_FUNCTION_URL }}|g" scripts.js
        sed -i "s|INITIALIZE_FUNCTION_URL|${{ env.INITIALIZE_FUNCTION_URL }}|g" scripts.js
        sed -i "s|DYNAMODB_TABLE_NAME|${{ env.DYNAMODB_TABLE_NAME }}|g" scripts.js
      env:
        LAMBDA_FUNCTION_URL: ${{ env.LAMBDA_FUNCTION_URL }}
        INITIALIZE_FUNCTION_URL: ${{ env.INITIALIZE_FUNCTION_URL }}
        DYNAMODB_TABLE_NAME: ${{ env.DYNAMODB_TABLE_NAME }}
        BUCKET_NAME: ${{ env.BUCKET_NAME }}

    - name: Debug Environment Variables
      run: |
          echo "BUCKET_NAME=${{ env.BUCKET_NAME }}"
          echo "LAMBDA_FUNCTION_URL=${{ env.LAMBDA_FUNCTION_URL }}"
          echo "INITIALIZE_FUNCTION_URL=${{ env.INITIALIZE_FUNCTION_URL }}"
          echo "DYNAMODB_TABLE_NAME=${{ env.DYNAMODB_TABLE_NAME }}"
      env:
          LAMBDA_FUNCTION_URL: ${{ env.LAMBDA_FUNCTION_URL }}
          INITIALIZE_FUNCTION_URL: ${{ env.INITIALIZE_FUNCTION_URL }}
          DYNAMODB_TABLE_NAME: ${{ env.DYNAMODB_TABLE_NAME }}
          BUCKET_NAME: ${{ env.BUCKET_NAME }}

    - name: Upload updated scripts.js to S3
      if: ${{ env.LAMBDA_FUNCTION_URL && env.INITIALIZE_FUNCTION_URL && env.DYNAMODB_TABLE_NAME && env.BUCKET_NAME }}
      run: |
          aws s3 cp frontend/js/scripts.js s3://${{ env.BUCKET_NAME }}/js/scripts.js
      env:
          LAMBDA_FUNCTION_URL: ${{ env.LAMBDA_FUNCTION_URL }}
          INITIALIZE_FUNCTION_URL: ${{ env.INITIALIZE_FUNCTION_URL }}
          DYNAMODB_TABLE_NAME: ${{ env.DYNAMODB_TABLE_NAME }}
          BUCKET_NAME: ${{ env.BUCKET_NAME }}